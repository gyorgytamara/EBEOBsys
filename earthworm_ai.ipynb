{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBEOBsys\n",
    "\n",
    "This document explains the architecture and training of U-net type ANN for recognition of earthworms in terrariums.\n",
    "\n",
    "To install the required packages use the following line:\n",
    "\n",
    "If using conda:\n",
    "\n",
    "```bash\n",
    "conda isntall tensorflow, numpy\n",
    "```\n",
    "\n",
    "otherwise: \n",
    "\n",
    "```bash\n",
    "pip install tensorflow, numpy\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import (Conv2D, Conv2DTranspose, Input,\n",
    "                                     Lambda, MaxPooling2D, concatenate)\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocessed the training an validation images and stored them in binary form using `numpy`.\n",
    "The dataset contained more than 10gb of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 816\n",
    "img_height = 608\n",
    "img_channels = 3\n",
    "\n",
    "train = np.load('data/train.npy', mmap_mode='r')\n",
    "targets = np.load('data/targets_train.npy', mmap_mode='r')\n",
    "test = np.load('data/test.npy', mmap_mode='r')\n",
    "test_targets = np.load('data/targets_test.npy', mmap_mode='r')\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net\n",
    "\n",
    "U-net is convolutional neural network that uses upsampling factors to propagate information from input to output withous loss of resolution. The network consists of contracting part and epxansive part, hence the U-shape architecture. Contracting part is a standard convolutional network with repeated convlutions and ReLu and max pooling operations. Expansive part contains up-convolutions and concatenations with high-resolution features from the contracting path.\n",
    "\n",
    "![https://ars.els-cdn.com/content/image/1-s2.0-S001670611931496X-gr3.jpg](https://ars.els-cdn.com/content/image/1-s2.0-S001670611931496X-gr3.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((img_height, img_width, img_channels))\n",
    "s = Lambda(lambda x: x/255) (inputs)\n",
    "\n",
    "# Contracting path\n",
    "c1 = Conv2D(filters=8, kernel_size=(3,3), padding='same', activation='relu') (s)\n",
    "c1 = Conv2D(filters=8, kernel_size=(3,3), padding='same', activation='relu') (c1)\n",
    "p1 = MaxPooling2D(pool_size=(2,2)) (c1)\n",
    "\n",
    "c2 = Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu') (p1)\n",
    "c2 = Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu') (c2)\n",
    "p2 = MaxPooling2D(pool_size=(2,2)) (c2)\n",
    "\n",
    "c3 = Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu') (p2)\n",
    "c3 = Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu') (c3)\n",
    "p3 = MaxPooling2D(pool_size=(2,2)) (c3)\n",
    "\n",
    "c4 = Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu') (p3)\n",
    "c4 = Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2,2)) (c4)\n",
    "\n",
    "c5 = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu') (p4)\n",
    "c5 = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu') (c5)\n",
    "\n",
    "# Expansive path\n",
    "u6 = Conv2DTranspose(filters=64, kernel_size=(2,2), strides=(2,2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(filters=64, kernel_size=(3,3), padding='same') (u6)\n",
    "c6 = Conv2D(filters=64, kernel_size=(3,3), padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(filters=32, kernel_size=(2,2), strides=(2,2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(filters=32, kernel_size=(3,3), padding='same') (u7)\n",
    "c7 = Conv2D(filters=32, kernel_size=(3,3), padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(filters=16, kernel_size=(2,2), strides=(2,2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(filters=16, kernel_size=(3,3), padding='same') (u8)\n",
    "c8 = Conv2D(filters=16, kernel_size=(3,3), padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(filters=8, kernel_size=(2,2), strides=(2,2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(filters=8, kernel_size=(3,3), padding='same') (u9)\n",
    "c9 = Conv2D(filters=8, kernel_size=(3,3), padding='same') (c9)\n",
    "outputs = Conv2D(filters=1, kernel_size=(1,1), activation='softmax') (c9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "opt = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mname = 'model_2000'\n",
    "checkpointer = ModelCheckpoint('models/'+mname, verbose=0, save_best_only=True)\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='models/model_2000_graph', histogram_freq=0, write_graph=True, write_images=False)\n",
    "results = model.fit(train, targets, validation_data=(test, test_targets), batch_size=8, epochs=6000, initial_epoch=0, callbacks=[checkpointer, tbCallBack])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17cd2503db655b64897c05283269d3580dc722bf57cecabda2071d13773ab5c8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
